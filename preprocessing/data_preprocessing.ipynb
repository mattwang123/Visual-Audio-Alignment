{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from trim_videos import trim_videos\n",
    "from generate_neg_samples import generate_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert txt annotations to csv\n",
    "   - Input: Original AVE dataset annotations in `../data_samples/dataset info/Annotations.txt` \n",
    "   - Output: `ave_annotations_preprocessed.csv` with columns: Category, VideoID, Quality, StartTime, EndTime, Duration\n",
    "   - Purpose: Makes the annotations more accessible and easier to work with in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the parsed data\n",
    "annotations = []\n",
    "\n",
    "# Read the file line by line\n",
    "with open('../data_samples/dataset info/Annotations.txt', 'r') as file:\n",
    "    # Skip the header line\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        # Split the line into components\n",
    "        parts = line.strip().split('&')\n",
    "        if len(parts) == 5:  # Ensure the line has all 5 fields\n",
    "            category, video_id, quality, start_time, end_time = parts\n",
    "            annotations.append({\n",
    "                'Category': category,\n",
    "                'VideoID': video_id,\n",
    "                'Quality': quality,\n",
    "                'StartTime': float(start_time),\n",
    "                'EndTime': float(end_time)\n",
    "            })\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df = pd.DataFrame(annotations)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_qualities = df['Quality'].unique()\n",
    "print(\"Unique Quality Values:\", unique_qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_annotations(input_file: str, output_csv: str) -> None:\n",
    "    \"\"\"\n",
    "    Parse the AVE dataset annotations file and save as a CSV.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input `annotations.txt` file.\n",
    "        output_csv (str): Path to save the output CSV file.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store parsed data\n",
    "    annotations = []\n",
    "    \n",
    "    # Read and parse the file\n",
    "    with open(input_file, 'r') as file:\n",
    "        # Skip the header line\n",
    "        next(file)\n",
    "        \n",
    "        for line in file:\n",
    "            # Split each line into components\n",
    "            parts = line.strip().split('&')\n",
    "            \n",
    "            # Ensure the line has all 5 fields\n",
    "            if len(parts) == 5:\n",
    "                category, video_id, quality, start_time, end_time = parts\n",
    "                \n",
    "                # Calculate duration (optional)\n",
    "                duration = float(end_time) - float(start_time)\n",
    "                \n",
    "                # Store parsed data\n",
    "                annotations.append({\n",
    "                    'Category': category,\n",
    "                    'VideoID': video_id,\n",
    "                    'Quality': quality,\n",
    "                    'StartTime': float(start_time),\n",
    "                    'EndTime': float(end_time),\n",
    "                    'Duration': duration  # Optional field\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(annotations)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Preprocessed data saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated data to csv file for easier use\n",
    "input_file = \"../data_samples/dataset info/Annotations.txt\"  \n",
    "output_csv = \"ave_annotations_preprocessed.csv\"  # Output CSV path\n",
    "preprocess_annotations(input_file, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trim videos according to annotations\n",
    "The annotations contain the `StartTime` and `EndTime` of the youtube videos used for AVE training, however, the videos in the given dataset is not trimmed.\n",
    "\n",
    "We saved the trimmed clips in `../data_samples/dataset info/trimmed_clips.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"ave_annotations_preprocessed.csv\") \n",
    "# video_dir = \"../original_videos\"  # Folder with downloaded YouTube videos\n",
    "# output_dir = \"../data_samples/trimmed_clips\"   # Folder to save trimmed segments\n",
    "\n",
    "# trim_videos(df, video_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate synthetic bad samples using existing videos \n",
    "In order to create a balanced dataset with both positive (aligned) and negative (misaligned) samples, we utilized original videos and preprocessed annotations to\n",
    "    - Generated video samples in `generated_samples` directory\n",
    "    - Saved metadata in `generated_samples_metadata.csv`\n",
    "  \n",
    "Types of misalignments we used:\n",
    "   - Time shift: Audio delay relative to video\n",
    "   - Noise: Added white noise to audio\n",
    "   - Mute: Removed audio track\n",
    "   - Distort: Audio waveform distortion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ave_annotations_preprocessed.csv\")\n",
    "generate_samples(\n",
    "    df,\n",
    "    video_dir=\"../original_videos\",  # Full videos (not pre-trimmed)\n",
    "    output_dir=\"../data_samples/generated_samples\",\n",
    "    output_csv=\"generated_samples_metadata.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
